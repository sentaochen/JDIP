{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import scipy.linalg as la\n",
    "from sklearn.svm import SVC\n",
    "from JDIP import JDIP\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import scale,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readData(sc,tg): \n",
    "    data = sio.loadmat('DomainAdaptationDatasets/OC10_vgg6/' + sc + '.mat')# source domain \n",
    "    Xs,ys = data['FTS'].astype(np.float64),data['LABELS'].ravel()\n",
    "    ys = LabelEncoder().fit(ys).transform(ys).astype(np.float64)\n",
    "\n",
    "    data = sio.loadmat('DomainAdaptationDatasets/OC10_vgg6/' + tg + '.mat')# target domain \n",
    "    Xt,yt = data['FTS'].astype(np.float64),data['LABELS'].ravel()\n",
    "    yt = LabelEncoder().fit(yt).transform(yt).astype(np.float64)\n",
    "    \n",
    "    Xs = Xs / la.norm(Xs,axis=1,keepdims=True)\n",
    "    Xt = Xt / la.norm(Xt,axis=1,keepdims=True)\n",
    "    return Xs,ys,Xt,yt\n",
    "\n",
    "domains = ['amazon','caltech','dslr','webcam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "details of each domain:\n",
      "domain:  amazon , (958L, 4096L) , (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]), array([ 92,  82,  94,  99, 100, 100,  99, 100,  94,  98], dtype=int64))\n",
      "domain:  caltech , (1123L, 4096L) , (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]), array([151, 110, 100, 138,  85, 128, 133,  94,  87,  97], dtype=int64))\n",
      "domain:  dslr , (157L, 4096L) , (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]), array([12, 21, 12, 13, 10, 24, 22, 12,  8, 23], dtype=int64))\n",
      "domain:  webcam , (295L, 4096L) , (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]), array([29, 21, 31, 27, 27, 30, 43, 30, 27, 30], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "estimator = LinearSVC()\n",
    "\n",
    "tarSamp_per_class = 3\n",
    "\n",
    "print 'details of each domain:'\n",
    "for sc in domains:\n",
    "    Xs,ys,Xt,yt = readData(sc,domains[0])\n",
    "    print 'domain: ',sc,',', Xs.shape,',',  np.unique(ys,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_partition(Xs,ys,samp_per_class,seed):\n",
    "    Xs_tr,ys_tr = [],[]\n",
    "    ys = ys.astype(np.int)\n",
    "    for i in np.unique(ys):\n",
    "        Xi,yi = Xs[ys==i],ys[ys==i]\n",
    "        np.random.seed(seed)\n",
    "        s = np.random.choice(len(yi),samp_per_class,replace=False)\n",
    "        Xi_tr,yi_tr = Xi[s].tolist(),yi[s].tolist()\n",
    "        Xs_tr.extend(Xi_tr),ys_tr.extend(yi_tr)\n",
    "\n",
    "    return np.array(Xs_tr),np.array(ys_tr)\n",
    "\n",
    "def target_partition(Xt,yt,samp_per_class,seed):\n",
    "    Xt_tr,yt_tr,Xt_te,yt_te = [],[],[],[]\n",
    "    yt = yt.astype(np.int)\n",
    "    for i in np.unique(yt):\n",
    "        Xi,yi = Xt[yt==i],yt[yt==i]\n",
    "        np.random.seed(seed) \n",
    "        s1 = np.random.choice(len(yi),samp_per_class,replace=False)\n",
    "        s2 = list(set(range(len(yi))) - set(s1))    \n",
    "        Xi_tr,yi_tr,Xi_te,yi_te = Xi[s1].tolist(),yi[s1].tolist(),Xi[s2].tolist(),yi[s2].tolist()\n",
    "        Xt_tr.extend(Xi_tr),yt_tr.extend(yi_tr),Xt_te.extend(Xi_te),yt_te.extend(yi_te)\n",
    "\n",
    "    return np.array(Xt_tr),np.array(yt_tr),np.array(Xt_te),np.array(yt_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.7637795276\n"
     ]
    }
   ],
   "source": [
    "Xs,ys,Xt,yt = readData('amazon','dslr')\n",
    "souSamp_per_class = 20 if sc == 'amazon' else 8\n",
    "Xs_sub,ys_sub = source_partition(Xs,ys,souSamp_per_class,10)\n",
    "Xtl,ytl,Xtu,ytu = target_partition(Xt,yt,tarSamp_per_class,10)\n",
    "                \n",
    "ytu0 = estimator.fit(np.vstack((Xs_sub,Xtl)),np.hstack((ys_sub,ytl))).predict(Xtu)\n",
    "W0 = PCA().fit(np.vstack((Xs_sub,Xt))).components_.T\n",
    "Ws,Wt = W0,W0\n",
    "for k in range(10):\n",
    "    Xt_,yt0_ = np.vstack((Xtl,Xtu)),np.hstack((ytl,ytu0))\n",
    "    W = JDIP(dimension=100,lamda=1e-5,sigma=.5,maxiter=5,verbosity=0).fit(Xs_sub,ys_sub,Xt_,yt0_,Ws,Wt)\n",
    "    Xs_sub_r,Xtl_r,Xtu_r = Xs_sub.dot(W[0]),Xtl.dot(W[1]),Xtu.dot(W[1])\n",
    "        \n",
    "    Xs_sub_r = Xs_sub_r / la.norm(Xs_sub_r,axis=1,keepdims=True)\n",
    "    Xtl_r = Xtl_r / la.norm(Xtl_r,axis=1,keepdims=True)\n",
    "    Xtu_r = Xtu_r / la.norm(Xtu_r,axis=1,keepdims=True)\n",
    "                \n",
    "    ytu0 = estimator.fit(np.vstack((Xs_sub_r,Xtl_r)),np.hstack((ys_sub,ytl))).predict(Xtu_r)\n",
    "    #print k, '-th iter.', estimator.score(Xtu_r,ytu)\n",
    "                                \n",
    "print estimator.fit(np.vstack((Xs_sub_r,Xtl_r)),np.hstack((ys_sub,ytl))).score(Xtu_r,ytu) * 100."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
